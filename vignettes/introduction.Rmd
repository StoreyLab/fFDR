---
title: "fFDR: Functional False Discovery Rate"
author: "David Robinson and John Storey"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{fFDR: Functional False Discovery Rate}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, echo = FALSE}
library(knitr)
opts_chunk$set(cache = TRUE, message = FALSE)
```

This vignette is still in progress, especially the text

Quick Start
-----------

```{r example_setup, echo = FALSE}
library(fFDR)
ttests_example <- simulate_t_tests(m = 2000)
p.value <- ttests_example$p.value
z <- ttests_example$n
```

You use fFDR when you have two vectors:

* `p.value`: p-values performed from many tests (typically at least 500, preferably more than 2500)
* `z`: a vector of the same length as `p.value` with information about the power of each hypothesis test

Perform fFDR control with the `fqvalue` function:

```{r example_fqvalue, dependson = "example_setup"}
fq <- fqvalue(p.value, z)
```

You can extract the functional q-values with:

```{r}
fqvalues <- fq$table$fq.value
sum(fqvalues < .05)
```

Simulation of t-tests
----------

### Simulation Setup

First, we set up a simulation of t-tests.

```{r simulate_t_tests}
library(fFDR)

set.seed(2015)
ttests <- simulate_t_tests(m = 5000)
```

This creates a data frame...

```{r dependson = "simulate_t_tests"}
head(ttests)
```

If we histogram the p-values, we see this.

```{r}
library(ggplot2)
ggplot(ttests, aes(p.value)) +
    geom_histogram()
```

Because this is a simulation, we know whether each hypothesis is null or alternative.

```{r}
library(ggplot2)
ggplot(ttests, aes(p.value, fill = oracle)) +
    geom_histogram()
```

```{r}
library(ggplot2)

ttests$bin <- cut(ttests$n, c(2, 3, 10, 40, Inf), include.lowest = TRUE)

ggplot(ttests, aes(p.value, fill = oracle)) +
    geom_histogram(binwidth = .1) +
    facet_wrap(~ bin, scales = "free_y")
```

Notice that t-tests with higher sample sizes lead to more anti-conservative p-value distributions: distributions that are more shifted towards 0. This means that the power is greater for higher sample sizes.

### Multiple hypothesis testing

```{r}
bonferroni_pvals <- p.adjust(ttests$p.value, method = "bonferroni")
sum(bonferroni_pvals < .05)
```

```{r}
fdr_pvals <- p.adjust(ttests$p.value, method = "fdr")
sum(fdr_pvals < .05)
```

```{r}
library(qvalue)
qvalues <- qvalue(ttests$p.value)$qvalues
sum(qvalues < .05)
```

Finally, we use fFDR control:

```{r}
library(fFDR)
fq <- fqvalue(ttests$p.value, ttests$n)
```

```{r}
fqvalues <- fq$table$fq.value
sum(fqvalues < .05)
```





